{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from nltk.tokenize import  word_tokenize\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from data_preprocessing import open_data, tokenize, tag_document, data_to_seq, glove_emb_matrix\n",
    "from validation import precision, recall, f1, retrive_phrase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/valeriya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "documents = {}\n",
    "labels = {}\n",
    "\n",
    "#directories\n",
    "dir_Tu= \"/Users/kmirai/Downloads/NLPProject-master/Hulth2003/Training\"\n",
    "\n",
    "dir_valeria_train = \"/home/valeriya/Desktop/UMD/Computational_linguistic/Project/Hulth2003/Hulth2003/Training\"\n",
    "dir_valeria_val = \"/home/valeriya/Desktop/UMD/Computational_linguistic/Project/Hulth2003/Hulth2003/Validation\"\n",
    "dir_valeria_test = \"/home/valeriya/Desktop/UMD/Computational_linguistic/Project/Hulth2003/Hulth2003/Test\"\n",
    "\n",
    "dir_anna = \"/Users/annasotnikova/Downloads/Hulth2003/Training\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#open data\n",
    "documents_train, labels_train = open_data(dir_valeria_train)\n",
    "documents_val, labels_val = open_data(dir_valeria_val)\n",
    "documents_test, labels_test = open_data(dir_valeria_test)\n",
    "\n",
    "# tokenize data\n",
    "tokenized_documents_train, tokenized_labels_train = tokenize(documents_train, labels_train)\n",
    "tokenized_documents_val, tokenized_labels_val = tokenize(documents_val, labels_val)\n",
    "tokenized_documents_test, tokenized_labels_test = tokenize(documents_test, labels_test)\n",
    "\n",
    "# create sequence of labels (tags) for the documents\n",
    "tags_train = tag_document(tokenized_documents_train, tokenized_labels_train)\n",
    "tags_val = tag_document(tokenized_documents_val, tokenized_labels_val)\n",
    "tags_test = tag_document(tokenized_documents_test, tokenized_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOVE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we download pretrained glove embeddings\n",
    "import numpy as np\n",
    "glove = dict()\n",
    "embed_size = 100\n",
    "f = open('glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    glove[word] = coefs\n",
    "f.close()\n",
    "\n",
    "glove_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create vocabulary from all data \n",
    "X_train_eng = [doc for doc in copy.deepcopy(tokenized_documents_train).values()]\n",
    "X_val_eng = [doc for doc in copy.deepcopy(tokenized_documents_val).values()]\n",
    "X_test_eng = [doc for doc in copy.deepcopy(tokenized_documents_test).values()]\n",
    "X_full = X_train_eng + X_val_eng + X_test_eng\n",
    "\n",
    "# Our vocab: all the words in all abstracts\n",
    "target_vocab = list(set([token for doc in X_full for token in doc]))\n",
    "# Dictionary with all words and their indices\n",
    "vocab_ind_dict = dict(zip(target_vocab, range(0, len(target_vocab)))) \n",
    "# Embedding matrix\n",
    "embed_matrix = glove_emb_matrix(vocab_ind_dict, glove, glove_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare data for network\n",
    "X_train = data_to_seq(X_train_eng, vocab_ind_dict)\n",
    "X_val = data_to_seq(X_val_eng, vocab_ind_dict)\n",
    "X_test = data_to_seq(X_test_eng, vocab_ind_dict)\n",
    "kp_train = [doc for doc in copy.deepcopy(tokenized_labels_train).values()]\n",
    "tags_train = [doc for doc in copy.deepcopy(tags_train).values()]\n",
    "kp_val = [doc for doc in copy.deepcopy(tokenized_labels_val).values()]\n",
    "tags_val = [doc for doc in copy.deepcopy(tags_val).values()]\n",
    "kp_test = [doc for doc in copy.deepcopy(tokenized_labels_test).values()]\n",
    "tags_test = [doc for doc in copy.deepcopy(tags_test).values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, nb_layers = 1, nb_lstm_units=150, nb_lin_units=150, embedding_dim=100, batch_size=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.vocab = target_vocab\n",
    "        self.nb_lstm_layers = nb_layers\n",
    "        self.nb_lstm_units = nb_lstm_units\n",
    "        self.nb_lin_units = nb_lin_units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_tags = 3\n",
    "        nb_vocab_words = len(self.vocab)\n",
    "\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.word_embedding = nn.Embedding(\n",
    "            num_embeddings=nb_vocab_words,\n",
    "            embedding_dim=self.embedding_dim)\n",
    "        self.word_embedding.load_state_dict({'weight': torch.Tensor(embed_matrix)})\n",
    "        self.word_embedding.weight.requires_grad = False\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.nb_lstm_units,\n",
    "            num_layers=self.nb_lstm_layers,\n",
    "            batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.drop = torch.nn.Dropout(p=0.25)\n",
    "\n",
    "        # linear layers\n",
    "        self.lin1 = nn.Linear(2*self.nb_lstm_units, self.nb_lin_units)\n",
    "        self.lin2 = nn.Linear(self.nb_lstm_units, self.nb_tags)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden_a = torch.randn(2, self.batch_size, self.nb_lstm_units).to(device)\n",
    "        hidden_b = torch.randn(2, self.batch_size, self.nb_lstm_units).to(device)\n",
    "        hidden_a = Variable(hidden_a)\n",
    "        hidden_b = Variable(hidden_b)\n",
    "\n",
    "        return (hidden_a, hidden_b)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "        X = self.word_embedding(X)\n",
    "        batch_size, seq_len, _ = X.size()\n",
    "\n",
    "        X, self.hidden = self.lstm(X, self.hidden)\n",
    "        X = self.drop(X)\n",
    "        X = X.contiguous()\n",
    "        X = X.view(-1, X.shape[2])\n",
    "        X = F.relu(self.lin1(X))\n",
    "        X = self.drop(X)\n",
    "        X = self.lin2(X)\n",
    "\n",
    "        X = X.view(batch_size, self.nb_tags, -1)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LSTM().to(device)\n",
    "weight = torch.tensor([1/10, 1, 1]).to(device)\n",
    "criterion= torch.nn.CrossEntropyLoss(weight)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epoch):\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, doc in enumerate(X):\n",
    "        inputs = torch.LongTensor(doc).view([1, len(doc)]).to(device)\n",
    "        labels = torch.LongTensor(y[i]).view([1, len(y[i])]).to(device) \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # compute predictions\n",
    "        outputs = (net(inputs))\n",
    "        # compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # statistics to display\n",
    "        train_loss += loss.item()\n",
    "        _,predicted = outputs.max(1)\n",
    "        total += labels[0].size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        #if i==0: \n",
    "        #    print(predicted)\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    print('Train Accuracy:', acc)\n",
    "    print('Train Loss:', train_loss)\n",
    "    return(train_loss)\n",
    "\n",
    "\n",
    "def document_prediction(document_seq, model):\n",
    "    inputs = torch.LongTensor(document_seq).view([1, len(document_seq)]).to(device) \n",
    "    outputs = (net(inputs))\n",
    "    _,predicted = outputs.max(1)\n",
    "    return predicted\n",
    "\n",
    "def validate(documents_eng, kp_eng, documents_seq, tags, model, epoch):\n",
    "    prec = 0\n",
    "    rec = 0\n",
    "    f_score = 0\n",
    "    acc = 0\n",
    "    for idx, document_eng in enumerate(documents_eng):\n",
    "        # our document\n",
    "        document_seq = documents_seq[idx]\n",
    "        kp_true = kp_eng[idx]\n",
    "        tags_true = tags[idx]\n",
    "        # predicted tags\n",
    "        tags_predicted = document_prediction(document_seq, model)\n",
    "        tags_predicted = tags_predicted.cpu().numpy()[0]\n",
    "        # predicted kp\n",
    "        kp_predicted = retrive_phrase(tags_predicted, document_eng)\n",
    "        # compute precision, recall, f_score, accuracy\n",
    "        prec += precision(kp_true, kp_predicted)\n",
    "        rec += recall(kp_true, kp_predicted)\n",
    "        f_score += f1(kp_true, kp_predicted)\n",
    "        acc += sum(np.equal(tags_true, tags_predicted))/len(tags_true)\n",
    "        if idx == 1 and epoch%10 == 0:\n",
    "            print(\"kp_true\",kp_true)\n",
    "            print(\"tags_predicted\", tags_predicted)\n",
    "            print(\"kp_predicted\", kp_predicted)\n",
    "    return prec/len(documents_eng), rec/len(documents_eng), f_score/len(documents_eng), acc/len(documents_eng)\n",
    "        \n",
    "        \n",
    "def main(num_epochs, net):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "        net = net.train() \n",
    "        train_loss = train(X_train, tags_train, epoch)\n",
    "        #get predictions, and labels, map\n",
    "        net = net.eval() \n",
    "        pr, r, f, acc = validate(X_val_eng, kp_val, X_val, tags_val, net, epoch)\n",
    "        print('Validation Accuracy:', acc) \n",
    "        print('Validation Precision:', pr)\n",
    "        print('Validation Recall:', r)\n",
    "        print('Validation F-score:', f) \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train Accuracy: 34.819946955621425\n",
      "Train Loss: 1093.2722862362862\n",
      "kp_true [['single-phase', 'half-bridge', 'rectifier', 'topology'], ['neutral', 'point', 'switch', 'clamped', 'scheme'], ['pwm', 'control', 'schemes'], ['power', 'quality', 'compensation'], ['sinusoidal', 'line', 'current'], ['current', 'distortion'], ['power', 'switches', 'control', 'signals'], ['dc', 'link', 'voltage', 'balance', 'compensator'], ['line', 'current', 'controller'], ['dc', 'link', 'voltage', 'regulator'], ['hysteresis', 'current', 'control', 'scheme'], ['line', 'current', 'command', 'tracking'], ['harmonic', 'currents', 'elimination'], ['circuit', 'configuration']]\n",
      "tags_predicted [2 2 1 2 2 1 2 2 1 2 2 1 2 2 1 2 2 1 2 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0\n",
      " 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2\n",
      " 1 0 2 1 0 1 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1\n",
      " 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 0 2 1 2]\n",
      "kp_predicted [['single-phase', 'half-bridge'], ['converter', 'topology', 'for'], ['power', 'quality', 'compensation'], ['a', 'high', 'power'], ['factor', 'half-bridge', 'rectifier'], ['with', 'neutral', 'point'], ['switch', 'clamped', 'scheme'], ['is'], ['.'], ['three'], ['switches'], ['are'], ['in'], ['the'], ['rectifier'], ['.'], ['pwm'], ['control'], ['are'], ['used'], ['draw'], ['a'], ['line'], ['current'], ['low'], ['current'], ['.'], ['the'], ['signals'], ['of'], ['power'], ['switches'], ['derived'], ['from'], ['dc'], ['link'], ['balance'], ['compensator'], ['line'], ['current'], ['and'], ['dc'], ['voltage'], ['regulator'], ['the'], ['hysteresis'], ['control'], ['scheme'], ['employed'], ['to'], ['the'], ['line'], ['command'], ['.'], ['proposed'], ['control'], ['and'], ['the'], ['configuration'], ['can'], ['applied'], ['to'], ['active'], ['power'], ['to'], ['eliminate'], ['harmonic'], ['currents'], ['compensate'], ['the'], ['power'], ['generated'], ['the'], ['nonlinear'], ['.'], ['analytical'], ['experimental'], ['results'], ['included'], ['to'], ['the'], ['validity'], ['effectiveness'], ['of'], ['proposed'], ['control', 'scheme']]\n",
      "Validation Accuracy: 0.3007996335750425\n",
      "Validation Precision: 0.024826715811384324\n",
      "Validation Recall: 0.13840184811845416\n",
      "Validation F-score: 0.04060085165997825\n",
      "\n",
      "Epoch: 1\n",
      "Train Accuracy: 47.191059043782886\n",
      "Train Loss: 1083.59354698658\n",
      "Validation Accuracy: 0.5348435596674724\n",
      "Validation Precision: 0.0245618004730615\n",
      "Validation Recall: 0.09424508267969314\n",
      "Validation F-score: 0.03582421986465749\n",
      "\n",
      "Epoch: 2\n",
      "Train Accuracy: 54.07760931538712\n",
      "Train Loss: 1075.5595726370811\n",
      "Validation Accuracy: 0.5783566158457517\n",
      "Validation Precision: 0.023789309137027655\n",
      "Validation Recall: 0.07226493878976652\n",
      "Validation F-score: 0.03262364797427941\n",
      "\n",
      "Epoch: 3\n",
      "Train Accuracy: 57.894960784035625\n",
      "Train Loss: 1065.4131653308868\n",
      "Validation Accuracy: 0.5363736445238857\n",
      "Validation Precision: 0.026114088788530956\n",
      "Validation Recall: 0.08120246076727307\n",
      "Validation F-score: 0.03603559149911585\n",
      "\n",
      "Epoch: 4\n",
      "Train Accuracy: 57.30494844483526\n",
      "Train Loss: 1055.146192073822\n",
      "Validation Accuracy: 0.5827860486741202\n",
      "Validation Precision: 0.026377645343115055\n",
      "Validation Recall: 0.07277172282272702\n",
      "Validation F-score: 0.034688488652373964\n",
      "\n",
      "Epoch: 5\n",
      "Train Accuracy: 56.79365169415803\n",
      "Train Loss: 1045.4067052304745\n",
      "Validation Accuracy: 0.5338120463037325\n",
      "Validation Precision: 0.025890913901316204\n",
      "Validation Recall: 0.08386385379416218\n",
      "Validation F-score: 0.0358901191276063\n",
      "\n",
      "Epoch: 6\n",
      "Train Accuracy: 56.81279872920419\n",
      "Train Loss: 1031.0626145601273\n",
      "Validation Accuracy: 0.5426530620385985\n",
      "Validation Precision: 0.02572564771965926\n",
      "Validation Recall: 0.08169230163078132\n",
      "Validation F-score: 0.03470215748090676\n",
      "\n",
      "Epoch: 7\n",
      "Train Accuracy: 55.97600238274214\n",
      "Train Loss: 1017.3752770572901\n",
      "Validation Accuracy: 0.516321610156375\n",
      "Validation Precision: 0.025130054103068917\n",
      "Validation Recall: 0.08316939968229384\n",
      "Validation F-score: 0.03459813147441359\n",
      "\n",
      "Epoch: 8\n",
      "Train Accuracy: 55.927071070957496\n",
      "Train Loss: 1002.2462363541126\n",
      "Validation Accuracy: 0.5204219148208371\n",
      "Validation Precision: 0.021710127949438426\n",
      "Validation Recall: 0.08092304223259138\n",
      "Validation F-score: 0.03244865472731721\n",
      "\n",
      "Epoch: 9\n",
      "Train Accuracy: 56.256825563419234\n",
      "Train Loss: 983.0112450644374\n",
      "Validation Accuracy: 0.5385074809353261\n",
      "Validation Precision: 0.02281647823717414\n",
      "Validation Recall: 0.0845548583451667\n",
      "Validation F-score: 0.034002502908640014\n",
      "\n",
      "Epoch: 10\n",
      "Train Accuracy: 56.62771072375792\n",
      "Train Loss: 963.924824565649\n",
      "kp_true [['single-phase', 'half-bridge', 'rectifier', 'topology'], ['neutral', 'point', 'switch', 'clamped', 'scheme'], ['pwm', 'control', 'schemes'], ['power', 'quality', 'compensation'], ['sinusoidal', 'line', 'current'], ['current', 'distortion'], ['power', 'switches', 'control', 'signals'], ['dc', 'link', 'voltage', 'balance', 'compensator'], ['line', 'current', 'controller'], ['dc', 'link', 'voltage', 'regulator'], ['hysteresis', 'current', 'control', 'scheme'], ['line', 'current', 'command', 'tracking'], ['harmonic', 'currents', 'elimination'], ['circuit', 'configuration']]\n",
      "tags_predicted [1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 2 1 1 2 1 1 2 0 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 1 0 2 2 0 0 2 0 0 0 0 0 2 2 0 1 2 2 1 2 0 1 0 2 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 2 2 2 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 2 1 0 1 1 0 0 1 0 2 1\n",
      " 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0]\n",
      "kp_predicted [['single-phase', 'half-bridge'], ['converter'], ['topology'], ['for'], ['power'], ['quality'], ['compensation'], ['a'], ['high'], ['power'], ['factor'], ['half-bridge', 'rectifier'], ['with'], ['neutral', 'point'], ['switch', 'clamped', 'scheme'], ['is'], ['proposed', '.'], ['three'], ['power', 'switches'], ['employed', 'in'], ['draw'], ['a'], ['line', 'current'], ['current'], ['of', 'the'], ['switches', 'are', 'derived'], ['from', 'the'], ['link'], ['balance'], ['compensator'], ['dc'], ['hysteresis'], ['employed', 'to', 'track'], ['line'], ['.'], ['the'], ['control'], ['scheme'], ['and'], ['the'], ['circuit'], ['configuration'], ['can'], ['applied'], ['to'], ['active'], ['power'], ['eliminate'], ['harmonic'], ['currents'], ['compensate'], ['the'], ['power'], ['generated'], ['nonlinear'], ['analytical'], ['and'], ['experimental'], ['results'], ['are'], ['included'], ['to'], ['validity'], ['control']]\n",
      "Validation Accuracy: 0.5262061731769161\n",
      "Validation Precision: 0.02263471568228882\n",
      "Validation Recall: 0.08348621803123227\n",
      "Validation F-score: 0.03398802103102007\n",
      "\n",
      "Epoch: 11\n",
      "Train Accuracy: 56.43907697108089\n",
      "Train Loss: 946.7183623109013\n",
      "Validation Accuracy: 0.525642169350944\n",
      "Validation Precision: 0.021360550003100102\n",
      "Validation Recall: 0.07793191400835302\n",
      "Validation F-score: 0.031706063493876495\n",
      "\n",
      "Epoch: 12\n",
      "Train Accuracy: 56.62629242486562\n",
      "Train Loss: 927.5829406753182\n",
      "Validation Accuracy: 0.5455758617672974\n",
      "Validation Precision: 0.022149869313774263\n",
      "Validation Recall: 0.08042358669411244\n",
      "Validation F-score: 0.03291653181886514\n",
      "\n",
      "Epoch: 13\n",
      "Train Accuracy: 57.1617002567121\n",
      "Train Loss: 905.920296494849\n",
      "Validation Accuracy: 0.5237212424684339\n",
      "Validation Precision: 0.02097055251245111\n",
      "Validation Recall: 0.07874886816276713\n",
      "Validation F-score: 0.031524883395794595\n",
      "\n",
      "Epoch: 14\n",
      "Train Accuracy: 57.80064390769711\n",
      "Train Loss: 882.0707056354731\n",
      "Validation Accuracy: 0.561613621398349\n",
      "Validation Precision: 0.02203484934320001\n",
      "Validation Recall: 0.07584856268004747\n",
      "Validation F-score: 0.03258502610498619\n",
      "\n",
      "Epoch: 15\n",
      "Train Accuracy: 58.467953536528285\n",
      "Train Loss: 864.5375580569962\n",
      "Validation Accuracy: 0.5414577493348635\n",
      "Validation Precision: 0.022320583076226447\n",
      "Validation Recall: 0.07952272331301614\n",
      "Validation F-score: 0.03288283129320408\n",
      "\n",
      "Epoch: 16\n",
      "Train Accuracy: 59.00619796615939\n",
      "Train Loss: 844.4564943171572\n",
      "Validation Accuracy: 0.5249035513279696\n",
      "Validation Precision: 0.021087534306518135\n",
      "Validation Recall: 0.07781446236470944\n",
      "Validation F-score: 0.031105562373048467\n",
      "\n",
      "Epoch: 17\n",
      "Train Accuracy: 59.52174961351355\n",
      "Train Loss: 821.1403212558216\n",
      "Validation Accuracy: 0.5385571471223445\n",
      "Validation Precision: 0.02160933300373665\n",
      "Validation Recall: 0.07971746476867098\n",
      "Validation F-score: 0.03230253216562241\n",
      "\n",
      "Epoch: 18\n",
      "Train Accuracy: 60.63440509452962\n",
      "Train Loss: 796.7871795986212\n",
      "Validation Accuracy: 0.5392554989450248\n",
      "Validation Precision: 0.02036946757120896\n",
      "Validation Recall: 0.0758819537046762\n",
      "Validation F-score: 0.03004336945581192\n",
      "\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 61.103152878437605\n",
      "Train Loss: 772.8805380536942\n",
      "Validation Accuracy: 0.5211996564622914\n",
      "Validation Precision: 0.020655575682192614\n",
      "Validation Recall: 0.07888103683389802\n",
      "Validation F-score: 0.03106611437602478\n",
      "\n",
      "Epoch: 20\n",
      "Train Accuracy: 62.38245847929993\n",
      "Train Loss: 753.2066877511679\n",
      "kp_true [['single-phase', 'half-bridge', 'rectifier', 'topology'], ['neutral', 'point', 'switch', 'clamped', 'scheme'], ['pwm', 'control', 'schemes'], ['power', 'quality', 'compensation'], ['sinusoidal', 'line', 'current'], ['current', 'distortion'], ['power', 'switches', 'control', 'signals'], ['dc', 'link', 'voltage', 'balance', 'compensator'], ['line', 'current', 'controller'], ['dc', 'link', 'voltage', 'regulator'], ['hysteresis', 'current', 'control', 'scheme'], ['line', 'current', 'command', 'tracking'], ['harmonic', 'currents', 'elimination'], ['circuit', 'configuration']]\n",
      "tags_predicted [1 2 2 1 2 1 1 1 2 1 1 1 1 2 2 1 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 2 0 2 0 2 2 0 0 2 0 2 2 1 0 1 1 2 2 1 0 1 1 2 1 1 2 2 0 0 1 1 1\n",
      " 0 2 0 0 1 1 0 0 0 2 2 0 1 0 0 1 1 0 0 1 1 1 1 0 2 0 2 2 2 2 1 0 0 1 0 2 2\n",
      " 0 2 2 2 0 1 2 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 0]\n",
      "kp_predicted [['single-phase', 'half-bridge', 'converter'], ['topology', 'for'], ['power'], ['quality'], ['compensation', 'a'], ['high'], ['power'], ['factor'], ['half-bridge', 'rectifier', 'with'], ['neutral', 'point', 'switch'], ['a', 'sinusoidal'], ['current'], ['low', 'current'], ['the'], ['signals', 'of'], ['the'], ['switches'], ['are', 'derived', 'from'], ['the'], ['link'], ['voltage', 'balance'], ['compensator'], [',', 'line', 'current'], ['dc'], ['link'], ['voltage'], ['.'], ['current'], ['control'], ['to', 'track'], ['line'], ['.'], ['the'], ['scheme'], ['and'], ['the'], ['circuit'], ['can'], ['applied', 'to', 'the', 'active'], ['power'], ['eliminate'], ['harmonic', 'currents'], ['compensate', 'the', 'reactive'], ['generated', 'from'], ['nonlinear'], ['load'], ['.'], ['and'], ['experimental'], ['are'], ['included'], ['illustrate'], ['the'], ['validity'], ['and'], ['control']]\n",
      "Validation Accuracy: 0.513453227161733\n",
      "Validation Precision: 0.0218536963961733\n",
      "Validation Recall: 0.08569018999882588\n",
      "Validation F-score: 0.033311997013835346\n",
      "\n",
      "Epoch: 21\n",
      "Train Accuracy: 62.9150297133618\n",
      "Train Loss: 730.067778271914\n",
      "Validation Accuracy: 0.5076352710601135\n",
      "Validation Precision: 0.02331459408494367\n",
      "Validation Recall: 0.08925758090468497\n",
      "Validation F-score: 0.03497848899514281\n",
      "\n",
      "Epoch: 22\n",
      "Train Accuracy: 64.28439729388572\n",
      "Train Loss: 708.8234020880627\n",
      "Validation Accuracy: 0.5059889988258873\n",
      "Validation Precision: 0.021344137126279673\n",
      "Validation Recall: 0.08536000024362066\n",
      "Validation F-score: 0.03256749774743083\n",
      "\n",
      "Epoch: 23\n",
      "Train Accuracy: 64.57656686570128\n",
      "Train Loss: 686.7094046552957\n",
      "Validation Accuracy: 0.5379105980714406\n",
      "Validation Precision: 0.020657694391502328\n",
      "Validation Recall: 0.07610952978095332\n",
      "Validation F-score: 0.030821821393609016\n",
      "\n",
      "Epoch: 24\n",
      "Train Accuracy: 65.75020919908661\n",
      "Train Loss: 666.821487241541\n",
      "Validation Accuracy: 0.5210486097414124\n",
      "Validation Precision: 0.024119729496281744\n",
      "Validation Recall: 0.08596514217897998\n",
      "Validation F-score: 0.03406794204327016\n",
      "\n",
      "Epoch: 25\n",
      "Train Accuracy: 66.33951238884083\n",
      "Train Loss: 646.8367425102042\n",
      "Validation Accuracy: 0.48317500914491285\n",
      "Validation Precision: 0.024160301531737403\n",
      "Validation Recall: 0.09480822134447132\n",
      "Validation F-score: 0.035028295925474316\n",
      "\n",
      "Epoch: 26\n",
      "Train Accuracy: 67.26778901385678\n",
      "Train Loss: 629.2110778209753\n",
      "Validation Accuracy: 0.5189215555281446\n",
      "Validation Precision: 0.022083634201561442\n",
      "Validation Recall: 0.0863786516781853\n",
      "Validation F-score: 0.03365930698938624\n",
      "\n",
      "Epoch: 27\n",
      "Train Accuracy: 68.1471343270881\n",
      "Train Loss: 607.6281886778597\n",
      "Validation Accuracy: 0.5191375737310372\n",
      "Validation Precision: 0.01977719379223245\n",
      "Validation Recall: 0.0793683506638589\n",
      "Validation F-score: 0.030452819375055413\n",
      "\n",
      "Epoch: 28\n",
      "Train Accuracy: 69.07186520487328\n",
      "Train Loss: 584.4713156357957\n",
      "Validation Accuracy: 0.5375898473059506\n",
      "Validation Precision: 0.021305270299539006\n",
      "Validation Recall: 0.0849978849040911\n",
      "Validation F-score: 0.03281940213729883\n",
      "\n",
      "Epoch: 29\n",
      "Train Accuracy: 69.84058320450451\n",
      "Train Loss: 570.1715890241321\n",
      "Validation Accuracy: 0.5132793057952462\n",
      "Validation Precision: 0.022642617040677403\n",
      "Validation Recall: 0.09314799383114916\n",
      "Validation F-score: 0.034978847357395766\n"
     ]
    }
   ],
   "source": [
    "main(30, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
