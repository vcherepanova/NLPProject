{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.utils.tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/valeriya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "documents = {}\n",
    "labels = {}\n",
    "\n",
    "# open main data\n",
    "for file in os.listdir(\"/home/valeriya/Desktop/UMD/Computational_linguistic/Project/Hulth2003/Hulth2003/Training\"):\n",
    "    if file.endswith(\".abstr\"):\n",
    "        content = open((\"%s/%s\" % ('/home/valeriya/Desktop/UMD/Computational_linguistic/Project/Hulth2003/Hulth2003/Training', file)), \"r\").read()\n",
    "        documents[file.split('.')[0]] = content.split('. ')\n",
    "        \n",
    "# open labels        \n",
    "for file in os.listdir(\"/home/valeriya/Desktop/UMD/Computational_linguistic/Project/Hulth2003/Hulth2003/Training\"):\n",
    "    if file.endswith(\".uncontr\"):\n",
    "        content = open((\"%s/%s\" % ('/home/valeriya/Desktop/UMD/Computational_linguistic/Project/Hulth2003/Hulth2003/Training', file)), \"r\").read()\n",
    "        labels[file.split('.')[0]] = content.split(\"; \")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize document\n",
    "tokenized_documents = {}\n",
    "for num, ctt in documents.items():\n",
    "    tokenized_documents[num] = []\n",
    "    for sentence in ctt:\n",
    "        words = nltk.word_tokenize(sentence.lower())\n",
    "        #words=[word.lower() for word in words if word.isalpha()]\n",
    "        tokenized_documents[num].append(words)\n",
    "\n",
    "# tokenize labels\n",
    "tokenized_labels = {}\n",
    "for num, ctt in labels.items():\n",
    "    tokenized_labels[num] = []\n",
    "    for sentence in ctt:\n",
    "        words = nltk.word_tokenize(sentence.lower())\n",
    "        #words=[word.lower() for word in words if word.isalpha()]\n",
    "        tokenized_labels[num].append(words)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PROBLEM \n",
    "# For document 1346 keyphrase should be \"growing time adaptive self-organizing map\", but word self-organized is lost\n",
    "# Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['automatic', 'multilevel', 'thresholding'],\n",
       " ['image', 'segmentation'],\n",
       " ['growing', 'time', 'adaptive', 'self-organizing', 'map'],\n",
       " ['growing', 'tasom'],\n",
       " ['gtasom'],\n",
       " ['peak', 'finding', 'process']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_labels['1346']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function find index of element in list of lists\n",
    "def index(lab, target):\n",
    "    for i,phr in enumerate(lab):\n",
    "        for j, w in enumerate(phr):\n",
    "            if w == target:\n",
    "                return (j)\n",
    "    return (None, None)\n",
    "\n",
    "# create dictionary of labels associated to words\n",
    "class_labels = copy.deepcopy(tokenized_documents)\n",
    "for document in tokenized_documents:\n",
    "    text = tokenized_documents[document]\n",
    "    lab = tokenized_labels[document]\n",
    "    lab_flattened = [val for sublist in lab for val in sublist]\n",
    "    for i, sentence in enumerate(text): \n",
    "        for j, word in enumerate(sentence): \n",
    "            is_keyphrase = word in lab_flattened\n",
    "            if is_keyphrase:\n",
    "                if index(tokenized_labels[document], word) == 0:\n",
    "                    class_labels[document][i][j] = \"first\"\n",
    "                else:\n",
    "                    class_labels[document][i][j] = 'inside'\n",
    "            else:\n",
    "                class_labels[document][i][j] = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['towards',\n",
       "  'a',\n",
       "  'nmr',\n",
       "  'implementation',\n",
       "  'of',\n",
       "  'a',\n",
       "  'quantum',\n",
       "  'lattice',\n",
       "  'gas',\n",
       "  'algorithm',\n",
       "  'recent',\n",
       "  'theoretical',\n",
       "  'results',\n",
       "  'suggest',\n",
       "  'that',\n",
       "  'an',\n",
       "  'array',\n",
       "  'of',\n",
       "  'quantum',\n",
       "  'information',\n",
       "  'processors',\n",
       "  'communicating',\n",
       "  'via',\n",
       "  'classical',\n",
       "  'channels',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'fluid',\n",
       "  'dynamics',\n",
       "  'problems'],\n",
       " ['quantum',\n",
       "  'lattice-gas',\n",
       "  'algorithms',\n",
       "  '(',\n",
       "  'qlga',\n",
       "  ')',\n",
       "  'running',\n",
       "  'on',\n",
       "  'such',\n",
       "  'architectures',\n",
       "  'have',\n",
       "  'been',\n",
       "  'shown',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'the',\n",
       "  'diffusion',\n",
       "  'equation',\n",
       "  'and',\n",
       "  'the',\n",
       "  'nonlinear',\n",
       "  'burgers',\n",
       "  'equations'],\n",
       " ['in',\n",
       "  'this',\n",
       "  'report',\n",
       "  ',',\n",
       "  'we',\n",
       "  'describe',\n",
       "  'progress',\n",
       "  'towards',\n",
       "  'an',\n",
       "  'ensemble',\n",
       "  'nuclear',\n",
       "  'magnetic',\n",
       "  'resonance',\n",
       "  '(',\n",
       "  'nmr',\n",
       "  ')',\n",
       "  'implementation',\n",
       "  'of',\n",
       "  'a',\n",
       "  'qlga',\n",
       "  'that',\n",
       "  'solves',\n",
       "  'the',\n",
       "  'diffusion',\n",
       "  'equation'],\n",
       " ['the',\n",
       "  'methods',\n",
       "  'rely',\n",
       "  'on',\n",
       "  'nmr',\n",
       "  'techniques',\n",
       "  'to',\n",
       "  'encode',\n",
       "  'an',\n",
       "  'initial',\n",
       "  'mass',\n",
       "  'density',\n",
       "  'into',\n",
       "  'an',\n",
       "  'ensemble',\n",
       "  'of',\n",
       "  'two-qubit',\n",
       "  'quantum',\n",
       "  'information',\n",
       "  'processors'],\n",
       " ['using',\n",
       "  'standard',\n",
       "  'pulse',\n",
       "  'techniques',\n",
       "  ',',\n",
       "  'the',\n",
       "  'mass',\n",
       "  'density',\n",
       "  'can',\n",
       "  'then',\n",
       "  'manipulated',\n",
       "  'and',\n",
       "  'evolved',\n",
       "  'through',\n",
       "  'the',\n",
       "  'steps',\n",
       "  'of',\n",
       "  'the',\n",
       "  'algorithm'],\n",
       " ['we',\n",
       "  'provide',\n",
       "  'the',\n",
       "  'experimental',\n",
       "  'results',\n",
       "  'of',\n",
       "  'our',\n",
       "  'first',\n",
       "  'attempt',\n",
       "  'to',\n",
       "  'realize',\n",
       "  'the',\n",
       "  'nmr',\n",
       "  'implementation'],\n",
       " ['the',\n",
       "  'results',\n",
       "  'qualitatively',\n",
       "  'follow',\n",
       "  'the',\n",
       "  'ideal',\n",
       "  'simulation',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'observed',\n",
       "  'implementation',\n",
       "  'errors',\n",
       "  'highlight',\n",
       "  'the',\n",
       "  'need',\n",
       "  'for',\n",
       "  'improved',\n",
       "  'control']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_documents['761']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nmr', 'implementation'],\n",
       " ['quantum', 'lattice', 'gas', 'algorithm'],\n",
       " ['quantum', 'information', 'processors'],\n",
       " ['fluid', 'dynamics', 'problems'],\n",
       " ['diffusion', 'equation'],\n",
       " ['nonlinear', 'burgers', 'equations'],\n",
       " ['nuclear', 'magnetic', 'resonance'],\n",
       " ['two-qubit', 'quantum', 'information.processors']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_labels['761']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'inside',\n",
       "  'no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'inside',\n",
       "  'inside',\n",
       "  'inside',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'inside',\n",
       "  'inside',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'inside',\n",
       "  'inside'],\n",
       " ['first',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'inside',\n",
       "  'no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'inside',\n",
       "  'inside'],\n",
       " ['no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'inside',\n",
       "  'inside',\n",
       "  'no',\n",
       "  'first',\n",
       "  'no',\n",
       "  'inside',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'inside'],\n",
       " ['no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'first',\n",
       "  'inside',\n",
       "  'inside'],\n",
       " ['no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'inside'],\n",
       " ['no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'first',\n",
       "  'inside'],\n",
       " ['no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'inside',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no',\n",
       "  'no']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels['761']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOVE embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings = dict()\n",
    "embed_size = 100\n",
    "f = open('glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for data we use sentences individually, not documents\n",
    "copy.deepcopy(tokenized_documents).values()\n",
    "X = [sent for doc in copy.deepcopy(tokenized_documents).values() for sent in doc]\n",
    "y = [sent for doc in copy.deepcopy(class_labels).values() for sent in doc]\n",
    "\n",
    "# padding the data\n",
    "def Padding(data):\n",
    "    len_max = len(max(X, key=lambda coll: len(coll)))\n",
    "    for i, sentence in enumerate(data):\n",
    "        len_sent = len(sentence)\n",
    "        len_pad = len_max - len_sent\n",
    "        sentence.extend(['PAD' for i in range(len_pad)])\n",
    "    return(data)\n",
    "\n",
    "X_padded = Padding(X)\n",
    "y_padded = Padding(y)\n",
    "X_lengths = len(X_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings['PAD'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, nb_layers = 1, nb_lstm_units=150, embedding_dim=100, batch_size=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.vocab = embeddings\n",
    "        self.tags = {'PAD': 0, 'first': 1, 'inside': 2, 'no': 3}\n",
    "\n",
    "        self.nb_lstm_layers = nb_layers\n",
    "        self.nb_lstm_units = nb_lstm_units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # don't count the padding tag for the classifier output\n",
    "        self.nb_tags = len(self.tags) - 1\n",
    "\n",
    "\n",
    "        nb_vocab_words = len(self.vocab)\n",
    "\n",
    "        # whenever the embedding sees the padding index it'll make the whole vector zeros\n",
    "        padding_idx = self.vocab['PAD']\n",
    "        print(padding_idx)\n",
    "        self.word_embedding = nn.Embedding(\n",
    "            num_embeddings=nb_vocab_words,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            padding_idx=padding_idx\n",
    "        )\n",
    "\n",
    "        # design LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.nb_lstm_units,\n",
    "            num_layers=self.nb_lstm_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # output layer which projects back to tag space\n",
    "        self.lin1 = nn.Linear(self.nb_lstm_units, nb_lstm_units)\n",
    "        self.lin2 = nn.Linear(self.nb_lstm_units, self.nb_tags)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden_a = torch.randn(self.hparams.nb_lstm_layers, self.batch_size, self.nb_lstm_units).to(device)\n",
    "        hidden_b = torch.randn(self.hparams.nb_lstm_layers, self.batch_size, self.nb_lstm_units).to(device)\n",
    "        hidden_a = Variable(hidden_a)\n",
    "        hidden_b = Variable(hidden_b)\n",
    "\n",
    "        return (hidden_a, hidden_b)\n",
    "\n",
    "    def forward(self, X, X_lengths):\n",
    "        # reset the LSTM hidden state. Must be done before you run a new batch. Otherwise the LSTM will treat\n",
    "        # a new batch as a continuation of a sequence\n",
    "        self.hidden = self.init_hidden()\n",
    "        batch_size, seq_len, _ = X.size()\n",
    "\n",
    "        # 1. embed the input\n",
    "        X = self.word_embedding(X)\n",
    "\n",
    "        # 2. Run through RNN\n",
    "        # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(x, X_lengths, batch_first=True)\n",
    "\n",
    "        # now run through LSTM\n",
    "        X, self.hidden = self.lstm(X, self.hidden)\n",
    "\n",
    "        # undo the packing operation\n",
    "        X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "\n",
    "        # 3. Project to tag space\n",
    "        # this one is a bit tricky as well. First we need to reshape the data so it goes into the linear layer\n",
    "        X = X.contiguous()\n",
    "        X = X.view(-1, X.shape[2])\n",
    "\n",
    "        # run through actual linear layer\n",
    "        X = F.relu(self.lin1(X))\n",
    "        X = F.relu(self.lin2(X))\n",
    "\n",
    "        # I like to reshape for mental sanity so we're back to (batch_size, seq_len, nb_tags)\n",
    "        X = X.view(batch_size, seq_len, self.nb_tags)\n",
    "\n",
    "        Y_hat = X\n",
    "        return Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valeriya/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "net = LSTM()\n",
    "criterion= torch.nn.CrossEntropyLoss(size_average=True, ignore_index=0)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Here we need function computing batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(X_padded):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        print(y_padded[i])\n",
    "        labels = torch.Tensor(y_padded[i]).to('device')\n",
    "        data = torch.Tensor(data).to('device')\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        _, outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # statistics\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    print('Train accuracy:', acc)\n",
    "    tb.add_scalar('Loss', train_loss, epoch)\n",
    "    tb.add_scalar('Accuracy', acc, epoch)\n",
    "    return(train_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'inside', 'inside', 'no', 'first', 'inside', 'no', 'no', 'first', 'inside', 'inside', 'inside', 'inside', 'no', 'no', 'no', 'no', 'no', 'first', 'inside', 'no', 'inside', 'inside', 'inside', 'inside', 'no', 'no', 'no', 'no', 'first', 'no', 'no', 'no', 'no', 'first', 'inside', 'inside', 'no', 'no', 'no', 'first', 'inside', 'inside', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-c3064034cdea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-0c1e5e649ea7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    train_loss = train(epoch)\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
